{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irvb37DISKwH"
      },
      "source": [
        "**ML Lab Assignment - 10 (Naive Bayes Classification)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0omwodtrSWwH"
      },
      "source": [
        "**Arya Chakraborty [22MSD7020]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EBfVmdzSda5"
      },
      "source": [
        "# Importing Dataset and the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C2FCSXAVReUk"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNMl9SzrSnpl"
      },
      "source": [
        "# Here we are considering only 3 categories from 20newsgroups dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCkjQSm7RwGh"
      },
      "outputs": [],
      "source": [
        "categories = ['sci.space', 'comp.graphics', 'rec.sport.baseball']  \n",
        "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
        "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO_8wClwTFnT"
      },
      "outputs": [],
      "source": [
        "print(\"Training Data:\")\n",
        "for i in range(5):\n",
        "    print(f\"Category: {train_data.target_names[train_data.target[i]]}\")\n",
        "    print(f\"Sample:\\n{train_data.data[i]}\")\n",
        "    print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmNKaenuS9DC"
      },
      "source": [
        "# Preprocessing & Vectorotizing the training and testing data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "5NChxZTCZh10"
      },
      "outputs": [],
      "source": [
        "def preprocess(document):\n",
        "    document = document.lower()\n",
        "    tokens = word_tokenize(document)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "    # Lemmatize the tokens\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    # joining the tokens \n",
        "    preprocessed_document = ' '.join(tokens)\n",
        "\n",
        "    return preprocessed_document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qANDC2pIRv_S"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "X_train = [preprocess(document) for document in train_data.data]\n",
        "X_test = [preprocess(document) for document in test_data.data]\n",
        "\n",
        "# vectorizing\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_preprocessed = vectorizer.fit_transform(train_data.data)\n",
        "X_test_preprocessed = vectorizer.transform(test_data.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "_AX6LCgfR1Am",
        "outputId": "3122dab1-41bf-4913-c12c-e23c4a408677"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_preprocessed, train_data.target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3hkqqHcFRkOt"
      },
      "outputs": [],
      "source": [
        "predictions = classifier.predict(X_test_preprocessed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZk8JyB5RkLL",
        "outputId": "bed501cf-a432-453c-edc4-b7e4653fdd48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9694915254237289\n"
          ]
        }
      ],
      "source": [
        "accuracy = accuracy_score(test_data.target, predictions)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5omuL9Z9YmMM"
      },
      "source": [
        "# further future prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "KVh-x1-hUtho"
      },
      "outputs": [],
      "source": [
        "new_document = \"\"\"\n",
        "Astronauts aboard the International Space Station conducted a spacewalk to repair\n",
        "a faulty solar panel. The spacewalk lasted for several hours and was successful in\n",
        "restoring power generation to the ISS. This mission marks an important milestone in\n",
        "space exploration and demonstrates the capabilities of human spaceflight.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riBcFAKpUtYR",
        "outputId": "66c07bcd-ab32-4f5b-eddb-8eb2d9754859"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcNoq_N2b30I"
      },
      "source": [
        "# user defined function for preprocessing the new document and predicting it's class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "N-AqKlQMV-a4"
      },
      "outputs": [],
      "source": [
        "def new_prediction(x):\n",
        "  # Preprocessing\n",
        "  preprocessed_document = preprocess(x)  \n",
        "  feature_vector = vectorizer.transform([preprocessed_document])\n",
        "\n",
        "  # Model prediction\n",
        "  predicted_class = classifier.predict(feature_vector)\n",
        "  predicted_class_index = predicted_class[0]\n",
        "  predicted_class_name = train_data.target_names[predicted_class_index]\n",
        "  print(\"Predicted Class:\", predicted_class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPc_Wug8V-Py",
        "outputId": "e861ed53-e41b-4ce8-bc0f-f02b2979f38f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: sci.space\n"
          ]
        }
      ],
      "source": [
        "new_prediction(new_document)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
